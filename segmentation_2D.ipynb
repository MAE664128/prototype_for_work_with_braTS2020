{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели для сегментации мозга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка среды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQX7R4bhZy5h",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "import tensorflow as tf\n",
    "from loader_data import PreprocessLoadData, AnimateView\n",
    "from models.model_MultiReaUNet2d import Model2DMultiResUnet\n",
    "from models.model_UNet2d import Model2DUnet\n",
    "import numpy as np\n",
    "\n",
    "num_gpu_device = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "if num_gpu_device == 1:\n",
    "    tf.config.set_visible_devices(tf.config.experimental.list_physical_devices('GPU')[0:1], 'GPU')\n",
    "    gpu_device = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "    tf.config.experimental.set_memory_growth(gpu_device, True)\n",
    "else:\n",
    "#     mirrored_strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "    \n",
    "\n",
    "    print('Количество GPU: {}'.format(mirrored_strategy.num_replicas_in_sync))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем ключевые параметры\n",
    "\n",
    " - **KERNEL_DIM** - Размер изображения которое подаем на вход сети. Независимо от размера исходного изображения, генератор будет делить исходное изображение на куски размером KERNEK_DIM\n",
    " - **STEP_WINDOW** - Разбиение исходного изображения на куски размером KERNEK_DIM происходит по принципу плавающего окна. STEP_WINDOW задает шаг смещения окна.\n",
    " - **BATCH_SIZE** - Количество кусков в одном батче\n",
    " - **Model** - Класс модели, которую будем обучать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_WINDOW = (64, 64)\n",
    "BATCH_SIZE = 16\n",
    "KERNEL_DIM = (256, 256)\n",
    "\n",
    "# Model2DMultiResUnet or Model2DUnet\n",
    "Model = Model2DMultiResUnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверяем наличие данных для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Находим обучающие данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = PreprocessLoadData(kernel_size=KERNEL_DIM, step=STEP_WINDOW, batch_size=BATCH_SIZE)\n",
    "loader.find_files()\n",
    "print(f\"Был найден набор из {loader.length_data()} пар данных\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получаем генератор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = loader.get_generator_data(\"train\",\n",
    "                                          threshold=0.1,\n",
    "                                          random_change_plane=False,\n",
    "                                          augmentation=False,\n",
    "                                          is_whitening=False\n",
    "                                         )\n",
    "test_dataset = loader.get_generator_data(\"test\",\n",
    "                                         threshold=0.1,\n",
    "                                         random_change_plane=False,\n",
    "                                         augmentation=False,\n",
    "                                         is_whitening=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверяем как работает генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    list_ax = [fig.add_subplot(1, len(display_list), i + 1) for i in range(len(display_list))]\n",
    "    list_exponenta = []\n",
    "    for i in range(len(display_list)):\n",
    "        plt.title(title[i])\n",
    "        list_exponenta.append((display_list[i].min(),display_list[i].max()))\n",
    "    list_ims = []\n",
    "    for ind_z in range(display_list[0].shape[0]):\n",
    "        if display_list[0][ind_z,...].max() == 0:\n",
    "            continue\n",
    "        ims = []\n",
    "        for i in range(len(display_list)):\n",
    "            cmap_val = 'gray' if i == 0 else \"viridis\"\n",
    "            im = list_ax[i].imshow(tf.keras.preprocessing.image.array_to_img(display_list[i][ind_z,...]),\n",
    "                           animated=True, cmap=cmap_val, vmin=list_exponenta[i][0], vmax=list_exponenta[i][1])\n",
    "            ims.append(im)\n",
    "        list_ims.append(ims)\n",
    "    ani = animation.ArtistAnimation(fig,\n",
    "                                    list_ims,\n",
    "                                    interval=50,\n",
    "                                    blit=True)\n",
    "    return ani\n",
    "\n",
    "\n",
    "for image, mask in train_dataset:\n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    sample_image, sample_mask = image, mask\n",
    "    break\n",
    "display([sample_image, sample_mask])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем модель\n",
    "\n",
    " - n_channels: Размер канала входных данных.\n",
    " - initial_learning_rate: Начальная скорость обучения модели.\n",
    " - n_classes: Количество классов, которые изучает модель .\n",
    " - start_val_filters: Количество фильтров, которые будет иметь первый слой в сети.\n",
    " - list_metrics: Список метрик, для обучения модели.\n",
    " - type_up_convolution: тип повышающего слоя. up_sampling_3d использует меньше памяти.\n",
    " - pool_size: Размер пула для максимальных операций объединения. Целое число или кортеж.\n",
    " - input_img_shape: Форма входных данных кортеж(3N) или целое число (если форма соответствует кубу).\n",
    " - depth: глубина модели. Уменьшение глубины может уменьшить объем памяти, необходимый для тренировки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_gpu_device == 1:\n",
    "    manager_model = Model(depth=5, start_val_filters=16, input_img_shape=KERNEL_DIM, n_classes=3, n_channels=3,\n",
    "                                        initial_learning_rate=1.0)\n",
    "\n",
    "else:\n",
    "    with mirrored_strategy.scope():\n",
    "        manager_model = Model(depth=5, start_val_filters=16, input_img_shape=KERNEL_DIM, n_classes=3, n_channels=3,\n",
    "                                            initial_learning_rate=1.0)\n",
    "model = manager_model.model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверяем как работает не обученная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for image, mask in train_dataset:\n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    pred_mask = manager_model.model.predict(image)\n",
    "    break\n",
    "display([image, mask, pred_mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 150\n",
    "\n",
    "total_pieces = (192 - BATCH_SIZE) // BATCH_SIZE + 1\n",
    "total_pieces *= (256 - KERNEL_DIM[-2]) // STEP_WINDOW[-2] + 1\n",
    "total_pieces *= (256 - KERNEL_DIM[-1]) // STEP_WINDOW[-1] + 1\n",
    "\n",
    "total_mri_study = (loader.length_data() * 0.8)\n",
    "total_mri_study = 2\n",
    "\n",
    "STEPS_PER_EPOCH = round(total_pieces * total_mri_study)\n",
    "# STEPS_PER_EPOCH = round(STEPS_PER_EPOCH * 0.6)\n",
    "VALIDATION_STEPS = round(2)\n",
    "\n",
    "early_stop_val = 20\n",
    "\n",
    "checkpoint_path = 'checkpoints2D//cp-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_directory = os.path.join(\"Results\", timestamp)\n",
    "\n",
    "# Добавление отображения через TensorBoard.\n",
    "log_dir = os.path.join(\"Results\",\n",
    "                       timestamp,\n",
    "                       \"logs\",\n",
    "                       \"fit\",\n",
    "                       datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "full_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                       save_weights_only=True,\n",
    "                                       save_freq=STEPS_PER_EPOCH,\n",
    "                                       verbose=1),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "                                   histogram_freq=1,\n",
    "                                   profile_batch=0,\n",
    "                                   write_images=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=early_stop_val)]\n",
    "\n",
    "model_history = manager_model.model.fit(train_dataset, epochs=EPOCHS,\n",
    "                                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                                        validation_steps=VALIDATION_STEPS,\n",
    "                                        validation_data=test_dataset,\n",
    "                                        verbose=1,\n",
    "                                        callbacks=full_callbacks)\n",
    "\n",
    "manager_model.model.save(f\"train.{Model.__name__}_{KERNEL_DIM}.{timestamp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_predictions(dataset=train_dataset, num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "segmentation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}